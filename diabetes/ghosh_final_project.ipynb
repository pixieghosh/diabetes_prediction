{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction\n",
    "data description (where from, what cols)\n",
    "goal/hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from matplotlib import pyplot\n",
    "import seaborn as sns \n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, f1_score \n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import SelectFpr, chi2\n",
    "\n",
    "import pickle "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BINARY ANALYSIS \n",
    "Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_bin = pd.read_csv('diabetes_binary_health_indicators_BRFSS2015.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data exploration\n",
    "correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = diabetes_bin.columns.tolist()\n",
    "for col in cols[1:]:\n",
    "    print(f' correlation for {col} : {diabetes_bin[\"Diabetes_binary\"].corr(diabetes_bin[col])}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "#split data first and do feature selection solely on split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train_bin, X_test_bin, y_train_bin, y_test_bin = train_test_split(diabetes_bin.iloc[:,1:], \n",
    "                                                    diabetes_bin['Diabetes_binary'], \n",
    "                                                    test_size= 0.20, random_state= 777, \n",
    "                                                    shuffle = True, stratify= diabetes_bin['Diabetes_binary'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature selection\n",
    "# create select fpr, fit transform with data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bin = SelectFpr(chi2, alpha=0.01).fit_transform(X_train_bin, y_train_bin)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest (random_state = 777, oob_score = True)\n",
    "# grid search (n_jobs = 4, cv = 5, return_train_score = True, scoring = ['f1_weighted','precision_weighted','recall_weighted','roc_auc'], refit = 'f1_weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_rf = {'n_estimators':np.arange(1000,4000,1000),\n",
    "          'max_depth':[13,14,15,16,None],\n",
    "          'max_features':['sqrt',0.5]}\n",
    "clf_rf_bin = RandomForestClassifier(random_state= 777, oob_score= True)\n",
    "gcv_rf_bin = GridSearchCV(clf_rf_bin, param_grid= params_rf, \n",
    "                   n_jobs = 4, cv = 5, \n",
    "                   return_train_score = True, \n",
    "                   scoring = ['f1_weighted'], \n",
    "                   refit = 'f1_weighted').fit(X_train_bin,y_train_bin)\n",
    "print(f'best validation F1 score: {gcv_rf_bin.cv_results_[\"mean_test_f1_weighted\"][gcv_rf_bin.best_index_]}')\n",
    "print(f'best training F1 score: {gcv_rf_bin.cv_results_[\"mean_train_f1_weighted\"][gcv_rf_bin.best_index_]}')\n",
    "print(f'best hyperparameters: {gcv_rf_bin.best_params_}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conf mat using training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf_bin = gcv_rf_bin.best_estimator_.predict(X_train_bin)\n",
    "conf_mat_rf_bin = confusion_matrix(y_true = y_train_bin, y_pred= y_pred_rf_bin)\n",
    "axes = sns.heatmap(conf_mat_rf_bin, cbar= False, annot= True, fmt = 'd', cmap=\"crest\")\n",
    "axes.set_xlabel('Predicted')\n",
    "axes.set_ylabel('True')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hist gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_hgb = {'max_iter':np.arange(1000,4000,1000),\n",
    "          'max_depth':[13,14,15,16,None],\n",
    "          'min_samples_leaf':[40,60,80,100],\n",
    "          'learning_rate': [0.001,0.01,0.1]}\n",
    "clf_hgb_bin = HistGradientBoostingClassifier(random_state= 777, categorical_features= [0,1,2,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19])\n",
    "gcv_hgb_bin = GridSearchCV(clf_hgb_bin, param_grid= params_hgb, n_jobs = 4, \n",
    "                   cv = 5, return_train_score = True, \n",
    "                   scoring = ['f1_weighted'], \n",
    "                   refit = 'f1_weighted').fit(X_train_bin,y_train_bin)\n",
    "\n",
    "print(f'best validation F1 score: {gcv_hgb_bin.cv_results_[\"mean_test_f1_weighted\"][gcv_hgb_bin.best_index_]}')\n",
    "print(f'best training F1 score: {gcv_hgb_bin.cv_results_[\"mean_train_f1_weighted\"][gcv_hgb_bin.best_index_]}')\n",
    "print(f'best hyperparameters: {gcv_hgb_bin.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_hgb_bin = gcv_hgb_bin.best_estimator_.predict(X_train_bin)\n",
    "conf_mat_hgb_bin = confusion_matrix(y_true = y_train_bin, y_pred= y_pred_hgb_bin)\n",
    "axes = sns.heatmap(conf_mat_hgb_bin, cbar= False, annot= True, fmt = 'd', cmap=\"crest\")\n",
    "axes.set_xlabel('Predicted')\n",
    "axes.set_ylabel('True')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_bin = gcv_hgb_bin.best_estimator_.predict(X_test_bin)\n",
    "conf_mat_test_bin = confusion_matrix(y_true = y_test_bin, y_pred= y_pred_test_bin)\n",
    "axes = sns.heatmap(conf_mat_test_bin, cbar= False, annot= True, fmt = 'd', cmap=\"crest\")\n",
    "axes.set_xlabel('Predicted')\n",
    "axes.set_ylabel('True')\n",
    "\n",
    "f1_score(y_test_bin, y_pred_test_bin, average= 'weighted')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiclass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_mc = pd.read_csv('diabetes_012_health_indicators_BRFSS2015.csv')\n",
    "diabetes_mc.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mc, X_test_mc, y_train_mc, y_test_mc = train_test_split(diabetes_mc.iloc[:,1:], \n",
    "                                                    diabetes_mc['Diabetes_012'], \n",
    "                                                    test_size= 0.20, random_state= 777, \n",
    "                                                    shuffle = True, \n",
    "                                                    stratify= diabetes_mc['Diabetes_012'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mc = SelectFpr(chi2, alpha=0.01).fit_transform(X_train_mc, y_train_mc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf_mc = RandomForestClassifier(random_state= 777, oob_score= True)\n",
    "gcv_rf_mc = GridSearchCV(clf_rf_mc, param_grid= params_rf, \n",
    "                   n_jobs = 4, cv = 5, \n",
    "                   return_train_score = True, \n",
    "                   scoring = ['f1_weighted'], \n",
    "                   refit = 'f1_weighted').fit(X_train_mc,y_train_mc)\n",
    "print(f'best validation F1 score: {gcv_rf_mc.cv_results_[\"mean_test_f1_weighted\"][gcv_rf_mc.best_index_]}')\n",
    "print(f'best training F1 score: {gcv_rf_mc.cv_results_[\"mean_train_f1_weighted\"][gcv_rf_mc.best_index_]}')\n",
    "print(f'best hyperparameters: {gcv_rf_mc.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf_mc = gcv_rf_mc.best_estimator_.predict(X_train_mc)\n",
    "conf_mat_rf_mc = confusion_matrix(y_true = y_train_mc, y_pred= y_pred_rf_mc)\n",
    "axes = sns.heatmap(conf_mat_rf_mc, cbar= False, annot= True, fmt = 'd', cmap=\"crest\")\n",
    "axes.set_xlabel('Predicted')\n",
    "axes.set_ylabel('True')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hist Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_hgb_mc = HistGradientBoostingClassifier(random_state= 777, categorical_features= [0,1,2,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19])\n",
    "gcv_hgb_mc = GridSearchCV(clf_hgb_mc, param_grid= params_hgb, n_jobs = 4, \n",
    "                   cv = 5, return_train_score = True, \n",
    "                   scoring = ['f1_weighted'], \n",
    "                   refit = 'f1_weighted').fit(X_train_mc,y_train_mc)\n",
    "\n",
    "print(f'best validation F1 score: {gcv_hgb_mc.cv_results_[\"mean_test_f1_weighted\"][gcv_hgb_mc.best_index_]}')\n",
    "print(f'best training F1 score: {gcv_hgb_mc.cv_results_[\"mean_train_f1_weighted\"][gcv_hgb_mc.best_index_]}')\n",
    "print(f'best hyperparameters: {gcv_hgb_mc.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_hgb_mc = gcv_hgb_mc.best_estimator_.predict(X_train_mc)\n",
    "conf_mat_hgb_mc = confusion_matrix(y_true = y_train_mc, y_pred= y_pred_hgb_mc)\n",
    "axes = sns.heatmap(conf_mat_hgb_mc, cbar= False, annot= True, fmt = 'd', cmap=\"crest\")\n",
    "axes.set_xlabel('Predicted')\n",
    "axes.set_ylabel('True')\n",
    "\n",
    "# use predict on test data, use f1 score function with weighted + do confusion matrix "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_mc = gcv_hgb_mc.best_estimator_.predict(X_test_mc)\n",
    "conf_mat_test_mc = confusion_matrix(y_true = y_test_mc, y_pred= y_pred_test_mc)\n",
    "axes = sns.heatmap(conf_mat_test_mc, cbar= False, annot= True, fmt = 'd', cmap=\"crest\")\n",
    "axes.set_xlabel('Predicted')\n",
    "axes.set_ylabel('True')\n",
    "\n",
    "f1_score(y_test_mc, y_pred_test_mc, average= 'weighted')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
